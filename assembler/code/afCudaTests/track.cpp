/*
 * track.cpp
 *
 *  Created on: Nov 20, 2015
 *      Author: nelaturi
 */

#include "track.h"
#include <opencv2/imgproc/imgproc.hpp>

// Global variables
Mat frame; //current frame
Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
int keyboard; //input from keyboard


void mat2array(cv::Mat& input, array& output)
{
	input.convertTo(input,CV_32FC3); // floating point
	const unsigned size = input.rows * input.cols;
	const unsigned w = input.cols;
	const unsigned h = input.rows;
	float r[size];
	float g[size];
	float b[size];
	int tmp = 0;
	for (unsigned i = 0; i < h; i++){
		for (unsigned j = 0; j < w; j++){
			Vec3f ip = input.at<Vec3f>(i,j);
			tmp = j*h + i; // convert to column major
			r[tmp] = ip[2];
			g[tmp] = ip[1];
			b[tmp] = ip[0];
		}
	}
	output = join(2,array(h,w,r),array(h,w,g), array(h,w,b))/255.f; //merge, set range [0-1]

}

int trackParticles(string input)
{
	try{

		// open the video file
		VideoCapture capture;
		if (input.empty())
			capture.open(0);
		else
			capture.open(input);
		if( !capture.isOpened() )
		{
			printf("\n Cannot open camera or video file\n");
			return -1;
		}

		 int frame_width=   capture.get(CV_CAP_PROP_FRAME_WIDTH);
		 int frame_height=   capture.get(CV_CAP_PROP_FRAME_HEIGHT);
		 VideoWriter video("out.avi",CV_FOURCC('M','J','P','G'),10, Size(frame_width,frame_height),true);


		//create GUI windows
		namedWindow("Frame");
		namedWindow("FG Mask MOG 2");
		//create Background Subtractor objects
		pMOG2 = createBackgroundSubtractorMOG2(700,150); //MOG2 approach

		/*It is also a Gaussian Mixture-based
		Background/Foreground Segmentation Algorithm.
		It is based on two papers by Z.Zivkovic, "Improved adaptive Gausian mixture model for background subtraction"
		in 2004 and "Efficient Adaptive Density Estimation per Image Pixel for the Task of Background Subtraction" in 2006.
		One important feature of this algorithm is that it selects the appropriate number of gaussian distribution
		for each pixel. (Remember, in last case, we took a K gaussian distributions
		throughout the algorithm).
		It provides better adaptibility to varying scenes due illumination changes etc.*/

		//read input data. ESC or 'q' for quitting
		while( (char)keyboard != 'q' && (char)keyboard != 27 ){
			//read the current frame
			if(!capture.read(frame)) {
				cerr << "Unable to read next frame." << endl;
				cerr << "Exiting..." << endl;
				exit(EXIT_FAILURE);
			}
			//update the background model
			std::clock_t start;
			//start = std::clock();
			//pMOG2->apply(frame, fgMaskMOG2);
			double t = (std::clock() - start) / (double)(CLOCKS_PER_SEC / 1000);
			//std::cout << "Time: " << t << " ms" << std::endl;
			//get the frame number and write it on the capture current frame
			stringstream ss;
			rectangle(frame, cv::Point(10, 2), cv::Point(100,20),
					cv::Scalar(255,255,255), -1);
			ss << capture.get(CAP_PROP_POS_FRAMES);
			string frameNumberString = ss.str();
			putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
					FONT_HERSHEY_SIMPLEX, 0.5 , cv::Scalar(0,0,0));
			//show the current frame and the fg masks
			//imshow("Frame", frame);
			imshow("FG Mask MOG 2", fgMaskMOG2);
			cvtColor(fgMaskMOG2,frame, COLOR_GRAY2RGB);
			video.write(frame);
			//get the input from the keyboard
			keyboard = waitKey( 30 );
		}
		//delete capture object
		capture.release();
		//destroy GUI windows
		destroyAllWindows();
		return EXIT_SUCCESS;


		/*
		 * edge detection
		Mat edges;
		namedWindow("edges",1);
		for(;;)
		{
			Mat frame;
			cap >> frame; // get a new frame from camera
			cvtColor(frame, edges, CV_BGR2GRAY);
			GaussianBlur(edges, edges, Size(7,7), 1.5, 1.5);
			Canny(edges, edges, 0, 30, 3);
			imshow("edges", edges);
			if(waitKey(30) >= 0) break;
		}
		 */

	}
	catch( cv::Exception& e ){
		const char* err_msg = e.what();
		std::cout << "opencv exception caught: " << err_msg << std::endl;
		throw;
	}
	return 0;
}

/*
af::array normalize(af::array a)
{
	float mx = af::max<float>(a);
	float mn = af::min<float>(a);
	return (a-mn)/(mx-mn);
}

void drawRectangle(af::array &out, unsigned x, unsigned y, unsigned dim0, unsigned dim1)
{
	//printf("\nMatching patch origin = (%u, %u)\n\n", x, y);
	seq col_span(x, x+dim0, 1);
	seq row_span(y, y+dim1, 1);
	//edge on left
	out(col_span, y       , 0) = 0.f;
	out(col_span, y       , 1) = 0.f;
	out(col_span, y       , 2) = 1.f;
	//edge on right
	out(col_span, y+dim1  , 0) = 0.f;
	out(col_span, y+dim1  , 1) = 0.f;
	out(col_span, y+dim1  , 2) = 1.f;
	//edge on top
	out(x       , row_span, 0) = 0.f;
	out(x       , row_span, 1) = 0.f;
	out(x       , row_span, 2) = 1.f;
	//edge on bottom
	out(x+dim0  , row_span, 0) = 0.f;
	out(x+dim0  , row_span, 1) = 0.f;
	out(x+dim0  , row_span, 2) = 1.f;
}


point templateMatch(af::array img, af::array chip, unsigned int width, unsigned int height, int x, int y, double &ct){
	// width/height = rectangle width/height
	// x,y = top left coordinates of bbox

	af::array region = img(seq(x, x+height, 1.0), seq(y, y+width, 1.0));
	//time template matching
	std::clock_t start;
	start = std::clock();
	af::array result_top_left = matchTemplate(region,chip);
	double t = (std::clock() - start) / (double)(CLOCKS_PER_SEC / 1000);
	std::cout << "Time (top-left): " << t << " ms" << std::endl;
	ct +=t;
	af::array disp_res = normalize(result_top_left);
	unsigned minLocation;
	float    minVal;
	min<float>(&minVal, &minLocation, disp_res);

	dim4 iDims = region.dims();
	point result;
	result.x = x+ minLocation%iDims[0];
	result.y = y + minLocation/iDims[0];

	return result;

}*/
